# Stable Diffusion ì •ë¦¬

<details>
<summary>ëª©ì°¨</summary>

1. [Overview](#1-overview)  
2. [Fundamental Principle](#2-fundamental-principle)  
â€ƒ2.1 [Embedding](#21-embedding)  
â€ƒ2.2 [Image Generation (Mapping & Interpolation)](#22-image-generation-mapping--interpolation)  
â€ƒ2.3 [Refine Image (Diffusion Process)](#23-refine-image-diffusion-process)  
3. [Detailed Architecture](#3-detailed-architecture)  
â€ƒ3.1 [CLIP (Text Encoder)](#31-clip-text-encoder)  
â€ƒâ€ƒ3.1.1 [Why CLIP?](#311-why-clip)  
â€ƒâ€ƒ3.1.2 [ì…ë ¥/í† í¬ë‚˜ì´ì§•/ì¶œë ¥](#312-ì…ë ¥í† í¬ë‚˜ì´ì§•ì¶œë ¥)  
â€ƒâ€ƒ3.1.3 [Cross-Attentionë¡œì˜ ì£¼ì…](#313-cross-attentionë¡œì˜-ì£¼ì…)  
â€ƒâ€ƒ3.1.4 [Classifier-Free Guidance (CFG)ì™€ Negative Prompt](#314-classifier-free-guidance-cfgì™€-negative-prompt)  
â€ƒ3.2 [VAE](#32-vae)  
â€ƒ3.3 [UNET](#33-unet)  
â€ƒ3.4 [Scheduler](#34-scheduler)  
4. [Stable Diffusionì˜ í•™ìŠµ ê³¼ì •](#4-stable-diffusionì˜-í•™ìŠµ-ê³¼ì •)  
5. [ê²°ê³¼ ë° íŠ¹ì§•](#5-ê²°ê³¼-ë°-íŠ¹ì§•)  
6. [Stable Diffusionì˜ ì˜ì˜](#6-stable-diffusionì˜-ì˜ì˜)  
7. [Stable Diffusionì˜ í™•ì¥ ëª¨ë¸](#7-stable-diffusionì˜-í™•ì¥-ëª¨ë¸)

</details>
---

## 1. Overview

**Stable Diffusion = Multimodal Generative AI**  
```
Input
â”œâ”€â”€ Text Prompt
â”œâ”€â”€ Image
â””â”€â”€ Other Modalities (sementic map, depth map, representations ...)

Process
â”œâ”€â”€ Text Encoding â†’ CLIP Transformer
â”œâ”€â”€ Image Encoding â†’ VAE Encoder â†’ Latent Space z
â”œâ”€â”€ Denoising & Refinement â†’ UNet + Diffusion Process
â””â”€â”€ Cross-Attention â†’ í…ìŠ¤íŠ¸ ì˜ë¯¸ì™€ ì‹œê° ì •ë³´ ê²°í•©

Output
â””â”€â”€ VAE Decoder â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„± (512Ã—512 ì´ìƒ)
```

- Latent Space ê¸°ë°˜ Diffusion â†’ íš¨ìœ¨ì  ì—°ì‚°

- ë©€í‹°ëª¨ë‹¬ ì…ë ¥ ì§€ì› â†’ ì–¸ì–´+ì‹œê° ìœµí•©

- í…ìŠ¤íŠ¸ë¡œë¶€í„° ì˜ë¯¸ì Â·ì‹œê°ì  ì¼ê´€ì„± ìˆëŠ” ì´ë¯¸ì§€ ìƒì„±

---

## 2. Fundamental Principle

pixel space ëŒ€ì‹  **latent space** ì—ì„œ denoising ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” íš¨ìœ¨ì  í™•ì‚° ëª¨ë¸.

| ë‹¨ê³„ | ì—­í•  | í•µì‹¬ ê¸°ìˆ  |
|------|------|-----------|
| 1. Embedding | í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ | **CLIP Text Encoder / Image Encoder** |
| 2. Image Generation | í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ì´ë¯¸ì§€ ë²¡í„°ë¡œ ë§¤í•‘ | **Neural Network (UNet)** |
| 3. Refinement | ë…¸ì´ì¦ˆ ì œê±° ê³¼ì •ì„ í†µí•´ ì´ë¯¸ì§€ë¥¼ ì„ ëª…í•˜ê²Œ | **Diffusion Model (Denoising)** |

---

### 2.1 Embedding

- **Text Embedding**  
  ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ì¥ì€ **CLIP(Contrastive Languageâ€“Image Pretraining)** ëª¨ë¸ì˜ Transformerë¥¼ í†µí•´  
  ì˜ë¯¸ì  ë²¡í„° ê³µê°„ìœ¼ë¡œ ë³€í™˜ëœë‹¤.  
  ì´ ë²¡í„°ëŠ” ëª¨ë¸ì´ ì´í•´í•˜ëŠ” â€˜semantic embeddingâ€™ì´ ëœë‹¤.

- **Image Embedding**  
  í•™ìŠµ ì¤‘ì—ëŠ” **VAE(Variational Autoencoder)**ì˜ Encoderê°€ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ **latent space**ë¡œ ì••ì¶•í•œë‹¤.  
  ì¦‰, ì¸ê°„ì´ ë³´ëŠ” pixel spaceê°€ ì•„ë‹ˆë¼, ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì €ì°¨ì› ë²¡í„° ê³µê°„ìœ¼ë¡œ ë³€í™˜ëœë‹¤.

> ğŸ’¡ "Human-perceivable â†’ Machine-interpretable (vector)"  
> Embedding ê³¼ì •ì„ í†µí•´ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ê°€ ê³µí†µ ê³µê°„ì—ì„œ ë§¤í•‘ëœë‹¤.

---

### 2.2 Image Generation (Mapping & Interpolation)

- **Neural Network**ë¥¼ í†µí•´ Text Vector â†” Image Vector ì‚¬ì´ì˜ ë§¤í•‘ ê´€ê³„ë¥¼ í•™ìŠµí•œë‹¤.  
- ë‘ ë²¡í„°ì˜ ì—°ì‚°ì´ â€œsemantic operationâ€ìœ¼ë¡œ ì‘ë™í•œë‹¤.  
  ì˜ˆë¥¼ ë“¤ì–´:  
  `vector("penguin") + vector("clown") â‰ˆ "penguin dressed as a clown"`
- ì´ëŸ¬í•œ ì„±ì§ˆì„ í†µí•´ **image interpolation**ì´ ê°€ëŠ¥í•˜ë‹¤.  
- ì¶œë ¥ì¸µì€ **sigmoid**ë¥¼ ì‚¬ìš©í•˜ì—¬ 0~1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, bias ë³´ì •ì„ í†µí•´ ì‹œê°ì  í’ˆì§ˆì„ ê°œì„ í•œë‹¤.

---

### 2.3 Refine Image (Diffusion Process)

- ì´ˆê¸°ì—ëŠ” íë¦¿í•˜ê³  ë…¸ì´ì¦ˆê°€ ë§ì€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤.  
- **Diffusion Model**ì€ ì´ ì´ë¯¸ì§€ë¥¼ ì ì§„ì ìœ¼ë¡œ Denoisingí•˜ë©°, ìµœì¢…ì ìœ¼ë¡œ ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì–»ëŠ”ë‹¤.

#### Diffusion Training Process
1. ì›ë³¸ ì´ë¯¸ì§€ì— **Gaussian noise**ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ì¶”ê°€ (forward process).  
2. ëª¨ë¸ì´ ì´ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë„ë¡ í•™ìŠµ (reverse process).  
3. í•™ìŠµì´ ì™„ë£Œëœ í›„ì—ëŠ” reverse processë¥¼ í†µí•´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤.

---

## 3. Detailed Architecture

Stable Diffusionì€ **Latent Diffusion Model (LDM)** êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘


'''
Text Prompt â†’ CLIP Text Encoder â†’ Text Embedding
â†“
Image â†’ VAE Encoder â†’ Latent Representation z
â†“
Noise ì¶”ê°€ â†’ UNet (Denoising)
â†‘
Cross-Attentionìœ¼ë¡œ Text ì •ë³´ ê²°í•©
â†“
VAE Decoder â†’ ìµœì¢… ì´ë¯¸ì§€
'''

- Diffusion ê³¼ì •ì€ **latent space**ì—ì„œ ìˆ˜í–‰ë˜ì–´ **ì—°ì‚°ëŸ‰ì„ ì ˆê°**í•¨
- latent spaceëŠ” VAE Encoderê°€ ìƒì„±í•œ ì••ì¶•ëœ í‘œí˜„ìœ¼ë¡œ, í”½ì…€ ê³µê°„ë³´ë‹¤ ì•½ 8~16ë°° ì‘ì€ ì°¨ì›ì„ ê°€ì§

---

### 3.1 CLIP (Text Encoder)

ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ë²¡í„°í™”í•œ `text embedding`ì„ ë§Œë“¤ì–´ UNetì˜ Cross-Attentionì— ê³µê¸‰    
â†’ ì–¸ì–´ ì˜ë¯¸ë¥¼ ì‹œê° í”¼ì²˜ì— ì£¼ì…í•´ **í…ìŠ¤íŠ¸ ì¡°ê±´ë¶€ ìƒì„±**ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.


#### 3.1.1 Why CLIP?
- **Multimodal alignment**: í…ìŠ¤íŠ¸â€“ì´ë¯¸ì§€ ìŒ ê¸°ë°˜ì˜ contrastive í•™ìŠµìœ¼ë¡œ ë‘ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ê°™ì€ semantic spaceì— ì •ë ¬
- **Generalization**: ê±°ëŒ€ ì›¹ ìŠ¤ì¼€ì¼ ë°ì´í„°ë¡œ í•™ìŠµë˜ì–´ **ìŠ¤íƒ€ì¼Â·ì½˜ì…‰íŠ¸** ì „ë°˜ì— ê°•í•œ ì¼ë°˜í™”
- **Lightweight at inference**: ì¸í¼ëŸ°ìŠ¤ì—ì„œëŠ” í…ìŠ¤íŠ¸ë§Œ ì¸ì½”ë”©í•˜ë¯€ë¡œ ë¹„ìš©ì´ ë‚®ìŒ(embedding ìºì‹œ ê°€ëŠ¥)

> ì°¸ê³ : Stable Diffusion 1.x/SDXLì€ CLIP ê³„ì—´ì„ ì‚¬ìš©í•¨ (í›„ì† ê³„ì—´/ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ì€ T5 ë“± ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ ì“°ê¸°ë„ í•¨. ì—¬ê¸°ì„œëŠ” CLIP ì‚¬ìš©ì„ ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª….)


#### 3.1.2 ì…ë ¥/í† í¬ë‚˜ì´ì§•/ì¶œë ¥

**Tokenization**: BPE ê¸°ë°˜ í† í¬ë‚˜ì´ì € ì‚¬ìš©. ì¼ë°˜ì ìœ¼ë¡œ **max length = 77 tokens** (SD 1.x/SDXL)
  - Tokenizationì€ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ì¥ì„ **ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ë‹¨ìœ„(í† í°)**ë¡œ ë¶„í• í•˜ëŠ” ê³¼ì •
    Stable Diffusionì˜ CLIPì€ ë‹¨ì–´ë¥¼ ì§ì ‘ ì´í•´í•˜ì§€ ì•Šê³ ,  
    ê° ë‹¨ì–´ë¥¼ **indexed embedding**ë¡œ ë³€í™˜í•´ì•¼ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.  

  - CLIPì€ **BPE(Byte Pair Encoding)** ê¸°ë°˜ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•œë‹¤.  
    - ê¸´ ë‹¨ì–´ë¥¼ ìì£¼ ë“±ì¥í•˜ëŠ” ë¶€ë¶„(subword) ë‹¨ìœ„ë¡œ ë¶„í• í•´ ì–´íœ˜ ìˆ˜ë¥¼ ì¤„ì´ë©´ì„œ ì˜ë¯¸ ë³´ì¡´.  
    - ex) â€œstrawberriesâ€ â†’ â€œstrawâ€, â€œberâ€, â€œriesâ€  
    - ì´ëŸ° ë°©ì‹ìœ¼ë¡œ **ìƒˆë¡œìš´ ë‹¨ì–´**ë‚˜ **ì² ì ë³€í˜•(ì˜ˆ: stylized, plural)** ë„ ì•ˆì •ì ìœ¼ë¡œ ì¸ì½”ë”© ê°€ëŠ¥

- ì…ë ¥ ë¬¸ì¥ì€ ë‹¤ìŒ ìˆœì„œë¡œ ì²˜ë¦¬ëœë‹¤
  1. **ë¬¸ì¥ ì •ê·œí™”**: ì†Œë¬¸ìí™”, ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° ë“± ì „ì²˜ë¦¬.  
  2. **Tokenization (BPE)**: ë¬¸ì¥ì„ subword ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê³  í† í° ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜.  
  3. **[BOS]/[EOS]/[PAD]** í† í° ì¶”ê°€: ë¬¸ì¥ì˜ ì‹œì‘/ë/ë¹ˆ ìë¦¬ í‘œì‹œìš©.  
  4. **ê¸¸ì´ ì œí•œ ì ìš©**: Stable Diffusionì˜ CLIPì€ **ìµœëŒ€ 77 tokens**ê¹Œì§€ë§Œ ì‚¬ìš©.  
     â†’ ì´ˆê³¼ ë¶€ë¶„ì€ **truncate**ë˜ì–´ ë¬´ì‹œë¨.  
     â†’ ë”°ë¼ì„œ ì¤‘ìš”í•œ ë‹¨ì–´ëŠ” **ë¬¸ì¥ ì•ë¶€ë¶„**ì— ë°°ì¹˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”.
 
  ex)Prompt: "A cute penguin wearing a clown costume"
    â†’ [BOS] a, cute, penguin, wearing, a, clown, costume, [EOS], [PAD]...
    â†’ token IDs: [49406, 320, 12345, 2891, 320, 7842, 9121, 49407, 0, ...]

ì¶œë ¥êµ¬ì¡° : 
  - **Per-token hidden states**
  - shape: `(B, T, D)`  
    - `B`: batch size  
    - `T`: token ìˆ˜ (â‰ˆ77)  
    - `D`: embedding dimension (ViT-L/14ì˜ ê²½ìš° 768)  
  - ê° í† í°ì´ ì˜ë¯¸ ë²¡í„°ë¡œ ë³€í™˜ë˜ì–´ UNetì˜ **Cross-Attention layer**ì—ì„œ K/V(Key/Value)ë¡œ ì‚¬ìš©ë¨.  
  - ì¦‰, ê° ë‹¨ì–´ê°€ ì´ë¯¸ì§€ ìƒì„± ê³¼ì •ì—ì„œ **ì–´ë–¤ ì‹œê°ì  ìš”ì†Œë¡œ ë°˜ì˜ë ì§€**ë¥¼ ê²°ì •.
  
  - **Pooled embedding (CLS/mean)**
  - shape: `(B, D)`  
  - ë¬¸ì¥ ì „ì²´ì˜ ì „ì—­ì  ì˜ë¯¸(global meaning)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°.  
  - SDXL ë“±ì—ì„œëŠ” **ì „ì²´ ìŠ¤íƒ€ì¼Â·ë¶„ìœ„ê¸°** ì œì–´ ì‹ í˜¸ë¡œ ì‚¬ìš©.

  

#### 3.1.3 Cross-Attentionë¡œì˜ ì£¼ì…
UNetì˜ ê° ë¸”ë¡ì—ì„œ **Q/K/V**ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±:
- `Q = W_Q * F` : UNetì˜ feature map(ê³µê°„ í•´ìƒë„ HÃ—Wë¥¼ í¼ì¹œ ì‹œí€€ìŠ¤)ì—ì„œ ì¶”ì¶œ  
- `K = W_K * E_text`, `V = W_V * E_text` : CLIPì˜ per-token embeddingì—ì„œ ì¶”ì¶œ  
- Attention:
  \[
  \mathrm{Attn}(Q,K,V) = \mathrm{softmax}\!\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
  \]
- ì§ê´€: UNet í”¼ì²˜ê°€ í…ìŠ¤íŠ¸ í† í°(ë‹¨ì–´/êµ¬)ì˜ ì˜ë¯¸ë¥¼ **ì„ íƒì ìœ¼ë¡œ ì°¸ì¡°**í•´ ì‹œê° ì„¸ë¶€ ë¬˜ì‚¬ì— ë°˜ì˜


#### 3.1.4 Classifier-Free Guidance (CFG)ì™€ Negative Prompt
- **Unconditional branch**: ë¹ˆ ë¬¸ìì—´ `""`(ë˜ëŠ” negative prompt)ë¡œ ì–»ì€ embeddingì„ ë³„ë„ë¡œ ê³„ì‚°
- **Guidance**:
  \[
  \hat{\epsilon} = \epsilon_{\text{uncond}} + s \cdot \big(\epsilon_{\text{cond}} - \epsilon_{\text{uncond}}\big)
  \]
  - \( s \): guidance scale (ê¶Œì¥ ë²”ìœ„ ì˜ˆ: **5â€“9**; ë„ˆë¬´ í¬ë©´ í¬ì¦ˆ/êµ¬ë„ ì™œê³¡, ë„ˆë¬´ ì‘ìœ¼ë©´ ì¡°ê±´ ì•½í™”)
- **Negative prompt**: ì›ì¹˜ ì•ŠëŠ” ê°œë…ì„ ëª…ì‹œ(ì˜ˆ: â€œblurry, low qualityâ€) â†’ **uncond** ëŒ€ì‹  **neg** ì„ë² ë”© ì‚¬ìš©

---

### 3.2 VAE


---

### 3.3 UNET

---

### 3.4 Scheduler


---

## 4. Stable Diffusionì˜ í•™ìŠµ ê³¼ì •

1. **ë°ì´í„° ì¤€ë¹„**: ì´ë¯¸ì§€â€“í…ìŠ¤íŠ¸ ìŒ(ì˜ˆ: LAION-5B)ì„ ì´ìš©  
2. **VAE í•™ìŠµ**: í”½ì…€ ì´ë¯¸ì§€ë¥¼ latent ê³µê°„ìœ¼ë¡œ ì¸ì½”ë”©  
3. **Diffusion í•™ìŠµ**: latent ê³µê°„ì—ì„œ ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸(UNet) í›ˆë ¨  
4. **CLIP í…ìŠ¤íŠ¸ ê²°í•©**: í…ìŠ¤íŠ¸â€“ì´ë¯¸ì§€ ìƒê´€ ê´€ê³„ë¥¼ í•™ìŠµ  
5. **ìƒ˜í”Œë§(Sampling)**: ì—­ diffusionìœ¼ë¡œ latent ë³µì› í›„ VAEë¡œ ë””ì½”ë”©

---

## 5. ê²°ê³¼ ë° íŠ¹ì§•

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì†ë„** | Latent Spaceì—ì„œ ì—°ì‚° â†’ Pixel Diffusionë³´ë‹¤ 4~10ë°° ë¹ ë¦„ |
| **í’ˆì§ˆ** | FID, IS ë“± ì£¼ìš” ì§€í‘œì—ì„œ GAN ëŒ€ë¹„ ìš°ìˆ˜ |
| **ìœ ì—°ì„±** | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, depth, segmentation ë“± ë‹¤ì–‘í•œ condition ì§€ì› |
| **í™•ì¥ì„±** | ControlNet, LoRA, DreamBooth ë“± ë‹¤ì–‘í•œ í™•ì¥ êµ¬ì¡°ì™€ ê²°í•© ê°€ëŠ¥ |

---

## 6. Stable Diffusionì˜ ì˜ì˜

- **ê³ í•´ìƒë„ ì´ë¯¸ì§€ í•©ì„±ì˜ ë¯¼ì£¼í™”**: ëˆ„êµ¬ë‚˜ GPU í•œë‘ ì¥ìœ¼ë¡œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥  
- **ë²”ìš©ì„±**: Text-to-Imageë¿ ì•„ë‹ˆë¼ Super-Resolution, Inpainting, Image-to-Imageê¹Œì§€ í™•ì¥  
- **íš¨ìœ¨ì„±**: Pixel-space Diffusion ëŒ€ë¹„ ìˆ˜ë°± ë°°ì˜ íš¨ìœ¨ í–¥ìƒ

---

## 7. Stable Diffusionì˜ í™•ì¥ ëª¨ë¸

| í™•ì¥ ê¸°ìˆ  | í•µì‹¬ ì•„ì´ë””ì–´ |
|------------|----------------|
| **ControlNet** | ì™¸ë¶€ ì¡°ê±´(Depth, Edge, Pose ë“±)ì„ ì œì–´ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš© |
| **LoRA** | ê°€ë²¼ìš´ fine-tuning ê¸°ë²• (ì €ë­í¬ ì ì‘) |
| **DreamBooth** | ê°œì¸ ë°ì´í„° ê¸°ë°˜ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ í•™ìŠµ |


---

## 8. í•œê³„ì  (Limitations)

- Sequential Samplingìœ¼ë¡œ ì¸í•´ GANë³´ë‹¤ ì—¬ì „íˆ ëŠë¦¼  
- Autoencoder í’ˆì§ˆì´ ì „ì²´ ê²°ê³¼ì— ì˜í–¥  
- Fine detail accuracy ì œí•œ  
- í…ìŠ¤íŠ¸ prompt í•´ì„ì˜ ëª¨í˜¸ì„± ì¡´ì¬



