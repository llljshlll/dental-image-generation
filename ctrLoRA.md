# CtrLoRA: AN EXTENSIBLE AND EFFICIENT FRAMEWORK FOR CONTROLLABLE IMAGE GENERATION

>  ì›ë¬¸ ë…¼ë¬¸: [ICLR 2025](https://github.com/xyfJASON/ctrlora)  
>  ì €ì: Yifeng Xu, Zhenliang He, Shiguang Shan, Xilin Chen

---

## 1. Overview

**CtrLoRA = Controllable Image-to-Image Generation Framework**  
```
Input
â”œâ”€â”€ Condition Image (Canny, Depth, Segmentation, Pose, etc.)
â”œâ”€â”€ Text Prompt (optional)
â””â”€â”€ Additional Conditions (multi-condition possible)

Process
â”œâ”€â”€ Condition Encoding â†’ Pretrained VAE â†’ Condition Embedding
â”œâ”€â”€ Base ControlNet â†’ ê³µí†µ I2I ì§€ì‹ í•™ìŠµ (shared backbone)
â”œâ”€â”€ LoRA (Low-Rank Adaptation) â†’ ì¡°ê±´ë³„ ì„¸ë¶€ íŠ¹ì„± í•™ìŠµ
â””â”€â”€ UNet Diffusion Backbone â†’ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ë° ì´ë¯¸ì§€ ë³µì›

Output
â””â”€â”€ Stable Diffusion Decoder (VAE) â†’ ì œì–´ëœ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±
```


- **Base + LoRA êµ¬ì¡°**  
  â†’ Base ControlNetì´ **ê³µí†µì ì¸ Image-to-Image ìƒì„± ì§€ì‹**ì„ í•™ìŠµí•˜ê³ ,  
    LoRAê°€ **ê° ì¡°ê±´ì˜ ê³ ìœ  íŠ¹ì„±**ì„ ì €ë¹„ìš©ìœ¼ë¡œ í•™ìŠµí•¨.

- **Few-shot Adaptation (1,000 images / <1hr on 1 GPU)**  
  â†’ ìƒˆë¡œìš´ ì¡°ê±´ ì¶”ê°€ ì‹œ **ControlNet ì „ì²´ ì¬í•™ìŠµ ì—†ì´**,  
    **LoRAë§Œ í•™ìŠµ**í•˜ì—¬ ë¹ ë¥´ê²Œ ì ì‘ ê°€ëŠ¥.

- **Multi-Conditional Generation ì§€ì›**  
  â†’ ì—¬ëŸ¬ LoRAë¥¼ ì¡°í•©í•´ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì—  
    **ë‹¤ì¤‘ ì¡°ê±´ ì œì–´ (ì˜ˆ: Segmentation + Lighting)** ê°€ëŠ¥.

- **Pretrained VAE ê¸°ë°˜ Condition Embedding**  
  â†’ ê¸°ì¡´ì˜ ë¬´ì‘ìœ„ CNN ëŒ€ì‹  Stable Diffusionì˜ **VAE Encoder**ë¥¼ í™œìš©í•´  
    ì¡°ê±´ ì´ë¯¸ì§€ë¥¼ ì ì¬ê³µê°„ì— ì„ë² ë”©í•¨.  
  â†’ í•™ìŠµ ìˆ˜ë ´ ì†ë„ í–¥ìƒ ë° ControlNetì˜ **Sudden Convergence í˜„ìƒ ì œê±°**.

---

## 2. Fundamental Principle

**CtrLoRA**ëŠ” ê¸°ì¡´ **ControlNet**ì˜ êµ¬ì¡°ë¥¼ í™•ì¥í•˜ì—¬,  
ì—¬ëŸ¬ ì¡°ê±´ ì´ë¯¸ì§€ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  ìƒˆë¡œìš´ ì¡°ê±´ì—ë„ ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆëŠ”  
**í™•ì¥í˜• Controllable Diffusion Framework**ì´ë‹¤.

| ë‹¨ê³„ | ì—­í•  | í•µì‹¬ ê¸°ìˆ  |
|------|------|-----------|
| 1. Condition Embedding | ì¡°ê±´ ì´ë¯¸ì§€ë¥¼ ì ì¬ê³µê°„(latent space)ìœ¼ë¡œ ë³€í™˜ | **Pretrained VAE Encoder** |
| 2. Base ControlNet | ê³µí†µì ì¸ I2I(image-to-image) ìƒì„± ì§€ì‹ í•™ìŠµ | **Shared UNet Backbone** |
| 3. Condition-specific LoRA | ì¡°ê±´ë³„ ì„¸ë¶€ íŠ¹ì„± í•™ìŠµ (ì €ë¹„ìš©, í™•ì¥ì„±) | **Low-Rank Adaptation (LoRA)** |
| 4. Image Denoising & Generation | ì¡°ê±´ ê¸°ë°˜ìœ¼ë¡œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë©° ì´ë¯¸ì§€ ìƒì„± | **Diffusion Process (DDIM / DPM)** |

---

### 2.1 Condition Embedding

- ê¸°ì¡´ ControlNetì€ **ë¬´ì‘ìœ„ ì´ˆê¸°í™”ëœ CNN**ì„ ì‚¬ìš©í•´ ì¡°ê±´ ì´ë¯¸ì§€ë¥¼ ì„ë² ë”©í–ˆìœ¼ë‚˜,  
  ì´ëŠ” í•™ìŠµ ì´ˆê¸°ì— ì˜ë¯¸ ìˆëŠ” í”¼ì²˜ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í•´ **ìˆ˜ë ´ì´ ëŠë¦¬ê³  ë¶ˆì•ˆì •**í–ˆë‹¤.  
- **CtrLoRAëŠ” Stable Diffusionì˜ Pretrained VAE Encoderë¥¼ ì‚¬ìš©**í•˜ì—¬  
  ì¡°ê±´ ì´ë¯¸ì§€ë¥¼ ì ì¬ê³µê°„ìœ¼ë¡œ ë³€í™˜í•œë‹¤.  
- ì´ ë°©ì‹ì€  
  - **ë¹ ë¥¸ ìˆ˜ë ´ (convergence)**  
  - **ì•ˆì •ì ì¸ í•™ìŠµ**  
  - **ControlNetì˜ sudden convergence í˜„ìƒ ì œê±°**  
  ë¥¼ ë™ì‹œì— ë‹¬ì„±í•œë‹¤.

> ğŸ’¡ â€œRandom CNN â†’ Pretrained VAEâ€  
> ì´ë¯¸ì§€ë¥¼ ì„ë² ë”©í•  ë•Œ, ì‚¬ì „ í•™ìŠµëœ VAEì˜ í‘œí˜„ ê³µê°„ì„ ê·¸ëŒ€ë¡œ í™œìš©í•˜ì—¬  
> í•™ìŠµ íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•¨.



### 2.2 Base ControlNet (Shared Backbone)

- ì—¬ëŸ¬ ì¡°ê±´(canny, depth, segmentation, skeleton ë“±)ì„ í•˜ë‚˜ì˜ ë„¤íŠ¸ì›Œí¬ë¡œ í•™ìŠµí•œë‹¤.  
- ëª¨ë“  condition ë°ì´í„°ë¥¼ **ê³µí†µ Loss Function** ì•„ë˜ì„œ í•™ìŠµí•˜ì—¬  
  **I2I(ì´ë¯¸ì§€-ì´ë¯¸ì§€) ìƒì„±ì˜ ì¼ë°˜ ì§€ì‹(common knowledge)** ì„ íšë“í•œë‹¤.  
- ê° conditionë³„ LoRAê°€ ì¶”ê°€ë˜ì–´, Base ControlNetì€  
  â€œê³µí†µì  êµ¬ì¡° í•™ìŠµâ€ì— ì§‘ì¤‘í•˜ê³ , LoRAëŠ” â€œì¡°ê±´ë³„ íŠ¹ìˆ˜ì„± í•™ìŠµâ€ì— ì§‘ì¤‘í•œë‹¤.

> ğŸ’¡ Base ControlNet = General I2I Knowledge Learner  
> LoRA = Condition Expert Module


### 2.3 Condition-specific LoRA (Low-Rank Adaptation)

- LoRAëŠ” í° weight í–‰ë ¬ì˜ ë³€í™”ë¥¼ **ì €ë­í¬ ë¶„í•´(Î”W = BA)** í˜•íƒœë¡œ ê·¼ì‚¬í•˜ì—¬  
  **í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ 90% ì´ìƒ ì ˆê°**í•œë‹¤.  
- ìƒˆë¡œìš´ ì¡°ê±´ ì¶”ê°€ ì‹œ, Base ControlNetì€ ê³ ì •í•˜ê³  LoRAë§Œ í•™ìŠµí•œë‹¤.  
- ì•½ **1,000ê°œ ì´ë¯¸ì§€ / 1ì‹œê°„ ë¯¸ë§Œ / ë‹¨ì¼ GPU (RTX 4090)** ìœ¼ë¡œë„ í•™ìŠµ ê°€ëŠ¥.  
- LoRA Rank = 128ë¡œ ì„¤ì • ì‹œ ì•½ **37M íŒŒë¼ë¯¸í„°**ë§Œ ì—…ë°ì´íŠ¸ë¨.

> ğŸ’¡ â€œTrain Once, Adapt Manyâ€  
> ControlNet ì „ì²´ë¥¼ ë‹¤ì‹œ í•™ìŠµí•˜ì§€ ì•Šê³ , LoRAë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ  
> ìƒˆë¡œìš´ conditionì„ ë¹ ë¥´ê²Œ ì§€ì› ê°€ëŠ¥.



### 2.4 Denoising & Image Generation (Diffusion Process)

- Base ControlNetê³¼ LoRAì˜ ì¶œë ¥ì€ Stable Diffusionì˜ UNetìœ¼ë¡œ ì „ë‹¬ë˜ì–´  
  **ì¡°ê±´ ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±°(reverse diffusion)** ë¥¼ ìˆ˜í–‰í•œë‹¤.  
- Sampling ë‹¨ê³„ì—ì„œëŠ” **DDIM(50 steps)** ë˜ëŠ” **DPM-Solver**ë¥¼ ì‚¬ìš©í•˜ë©°,  
  classifier-free guidance scaleì€ ì¼ë°˜ì ìœ¼ë¡œ **7.5**ë¡œ ì„¤ì •ëœë‹¤.  
- ì—¬ëŸ¬ LoRAë¥¼ í•©ì„±í•˜ë©´ **multi-conditional generation**ì´ ê°€ëŠ¥í•˜ë©°,  
  ê° ì¡°ê±´ì˜ ì˜í–¥ì€ ê°€ì¤‘ì¹˜ë¡œ ì¡°ì ˆí•  ìˆ˜ ìˆë‹¤.

---

## 3. Detailed Architecture

CtrLoRAëŠ” **ControlNet + LoRA + Pretrained VAE**ë¥¼ ê²°í•©í•œ  
**í™•ì¥í˜• Controllable Latent Diffusion êµ¬ì¡°**ë¡œ ì„¤ê³„ë˜ì–´ ìˆë‹¤.  

```
Condition Image â†’ Pretrained VAE Encoder â†’ Condition Embedding
â†“
Base ControlNet (shared backbone) + Condition-specific LoRA
â†“
UNet (Denoising Network)
â†‘
Cross-Attention â†’ Text ì¡°ê±´ ê²°í•© (optional)
â†“
VAE Decoder â†’ ì œì–´ëœ ì´ë¯¸ì§€ ë³µì›
```


- Diffusionì€ Stable Diffusionê³¼ ë™ì¼í•˜ê²Œ **latent space**ì—ì„œ ìˆ˜í–‰ë˜ì–´ íš¨ìœ¨ì   
- ControlNetì˜ êµ¬ì¡°ë¥¼ **Base + LoRA ëª¨ë“ˆ**ë¡œ ë¶„ë¦¬í•˜ì—¬ **í™•ì¥ì„±** í™•ë³´  
- Condition Embeddingì—ëŠ” **VAE Encoder**ë¥¼ ì‚¬ìš©í•´ í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ  

---

### 3.1 Base ControlNet (Shared Backbone)

Base ControlNetì€ **ì—¬ëŸ¬ ì¡°ê±´(Condition)**ì„ í•˜ë‚˜ì˜ ë„¤íŠ¸ì›Œí¬ë¡œ í†µí•© í•™ìŠµí•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ  
**ê³µìœ í˜• I2I(Image-to-Image) ìƒì„± ëª¨ë“ˆ**ì´ë‹¤.

#### 3.1.1 êµ¬ì¡° ê°œìš”
- ê¸°ë³¸ì ìœ¼ë¡œ Stable Diffusionì˜ **UNet encoder êµ¬ì¡°**ë¥¼ ë”°ë¥´ë©°,  
  ì…ë ¥ìœ¼ë¡œ condition featureë¥¼ ë°›ì•„ latent representationì„ ë³€í™˜í•œë‹¤.  
- ê° blockì€ ControlNetì˜ residual branchë¥¼ í¬í•¨í•˜ë©°,  
  Stable Diffusionì˜ feature flowì— ì¶”ê°€ ì •ë³´ë¥¼ ì£¼ì…í•œë‹¤.

| êµ¬ì„± ìš”ì†Œ | ì„¤ëª… |
|------------|------|
| **Encoder (SD Encoder ë³µì œ)** | Stable Diffusionì˜ UNet encoderë¥¼ ê·¸ëŒ€ë¡œ ë³µì œí•˜ì—¬ ì´ˆê¸°í™”. |
| **Residual Block** | Condition featureë¥¼ ê° stageì— ì£¼ì… (control signal). |
| **Skip Connection** | Base ControlNetê³¼ SDì˜ UNet ê°„ feature alignmentë¥¼ ìœ ì§€. |
| **Zero Convolution Layer** | ì´ˆê¸° ì˜í–¥ ìµœì†Œí™”ë¥¼ ìœ„í•´ ëª¨ë“  residual branchë¥¼ 0ìœ¼ë¡œ ì‹œì‘. |

> ğŸ’¡ Base ControlNetì€ SDì˜ UNet êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ê³µìœ í•˜ì§€ë§Œ,  
> ì…ë ¥ìœ¼ë¡œ condition featureë¥¼ ë°›ì•„ â€œcontrol-aware feature mapâ€ì„ í˜•ì„±í•¨.



#### 3.1.2 í•™ìŠµ ë°©ì‹
- Base ControlNetì€ **9ê°€ì§€ base condition** (Canny, Depth, Skeleton, Segmentation ë“±)ì„ ë™ì‹œì— í•™ìŠµ.  
- ê° ì¡°ê±´ì€ **ê°œë³„ LoRA**ê°€ ì—°ê²°ëœ í˜•íƒœë¡œ ì£¼ì…ë˜ë©°,  
  Base ControlNetì€ â€œê³µí†µì ì¸ I2I ìƒì„± ì§€ì‹â€ì„ í•™ìŠµí•œë‹¤.  
- í•™ìŠµ ì‹œ, ë°°ì¹˜ ë‹¨ìœ„ë¡œ conditionì„ ìˆœí™˜í•˜ë©° ë‹¤ìŒ ê³¼ì •ì„ ë°˜ë³µí•œë‹¤:
  1. í•œ ë²ˆì— í•˜ë‚˜ì˜ condition ë°ì´í„°ì…‹ì„ ì„ íƒ.  
  2. í•´ë‹¹ conditionì— ëŒ€ì‘í•˜ëŠ” LoRAë§Œ í™œì„±í™”.  
  3. Base ControlNetì˜ ê³µìœ  íŒŒë¼ë¯¸í„°ì™€ í•´ë‹¹ LoRAë¥¼ í•¨ê»˜ ì—…ë°ì´íŠ¸.  

> ğŸ’¡ ì—¬ëŸ¬ ì¡°ê±´ì„ **í•˜ë‚˜ì˜ ì†ì‹¤ í•¨ìˆ˜ë¡œ í†µí•©**í•´ í•™ìŠµí•˜ë¯€ë¡œ,  
> ê³µí†µëœ êµ¬ì¡°Â·ì¡°ëª…Â·í˜•íƒœ ë“±ì˜ ì‹œê°ì  íŒ¨í„´ì„ ì¼ë°˜í™”í•  ìˆ˜ ìˆë‹¤.



#### 3.1.3 ì—­í• 
- **ê³µí†µì  ì´ë¯¸ì§€ ìƒì„± ëŠ¥ë ¥ í•™ìŠµ (General I2I knowledge)**  
  â†’ ë‹¤ì–‘í•œ ì¡°ê±´ì„ í†µí•´ â€œì´ë¯¸ì§€ ë³€í™˜ì˜ ì¼ë°˜ ì›ë¦¬â€ë¥¼ ìŠµë“.  
- **LoRA í•™ìŠµì˜ ê¸°ë°˜ ëª¨ë¸ë¡œ ì‚¬ìš©**  
  â†’ Base ControlNetì„ ê³ ì •(freeze)í•˜ê³  LoRAë§Œ í•™ìŠµí•´ ìƒˆë¡œìš´ ì¡°ê±´ì— ë¹ ë¥´ê²Œ ì ì‘.  

> ğŸ’¡ ControlNetì„ ì¡°ê±´ë³„ë¡œ ìƒˆë¡œ í•™ìŠµí•˜ë˜ ê¸°ì¡´ ë°©ì‹ê³¼ ë‹¬ë¦¬,  
> CtrLoRAëŠ” Base ControlNetì„ í•œ ë²ˆë§Œ í•™ìŠµí•˜ë©´ ëœë‹¤.

---

### 3.2 LoRA (Low-Rank Adaptation)

LoRAëŠ” **Base ControlNet ìœ„ì— ë¶€ì°©ë˜ëŠ” ê²½ëŸ‰ ì ì‘ ëª¨ë“ˆ**ë¡œ,  
ê° conditionì˜ **ì„¸ë¶€ì  íŠ¹ì„±(local feature)**ì„ í•™ìŠµí•œë‹¤.

#### 3.2.1 í•µì‹¬ ê°œë…
- ê¸°ì¡´ full fine-tuningì—ì„œëŠ” ëª¨ë“  weight \( W \)ë¥¼ ì§ì ‘ ì—…ë°ì´íŠ¸í•´ì•¼ í•˜ì§€ë§Œ,  
  LoRAëŠ” weight ë³€í™”ë¥¼ **ì €ë­í¬ ê·¼ì‚¬(Î”W = BÂ·A)** ë¡œ í‘œí˜„í•œë‹¤.  
  - \( A \in \mathbb{R}^{r \times d} \), \( B \in \mathbb{R}^{d \times r} \), \( r \ll d \)
- í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì•½ **90% ì´ìƒ ê°ì†Œ**í•˜ë©°,  
  Base ControlNetì˜ íŒŒë¼ë¯¸í„°ëŠ” ê³ ì •ëœ ìƒíƒœë¡œ ìœ ì§€ëœë‹¤.

| êµ¬ì„± ìš”ì†Œ | ì„¤ëª… |
|------------|------|
| **Î”W = BÂ·A (rank = 128)** | LoRAì˜ ì €ë­í¬ ì—…ë°ì´íŠ¸ í–‰ë ¬ (rankëŠ” 128ë¡œ ì„¤ì •) |
| **Trainable Layer** | Base ControlNetì˜ ê° Linear/Conv ë ˆì´ì–´ë§ˆë‹¤ LoRA ë¶€ì°© |
| **Frozen Backbone** | Base ControlNetì˜ íŒŒë¼ë¯¸í„°ëŠ” ê³ ì •ë¨ |
| **Lightweight Parameter** | ì•½ 37M íŒŒë¼ë¯¸í„° (ControlNet ëŒ€ë¹„ 1/10 ìˆ˜ì¤€) |



#### 3.2.2 í•™ìŠµ ë° ì ìš©
1. Base ControlNetì„ ê³ ì •í•˜ê³ , ìƒˆë¡œìš´ condition ë°ì´í„°ë¡œ LoRAë¥¼ í•™ìŠµ.  
2. LoRAëŠ” ê° Linear Layerì˜ **Residual Update** í˜•íƒœë¡œ ì‚½ì…ë¨.  
3. í•™ìŠµ ì™„ë£Œ í›„, LoRAë¥¼ Base ControlNetê³¼ í•©ì„±í•˜ì—¬ inference ìˆ˜í–‰:
   \[
   W' = W + \Delta W = W + BA
   \]
4. ì—¬ëŸ¬ LoRAë¥¼ ë™ì‹œì— í•©ì‚°í•˜ì—¬ **Multi-Conditional Generation** ê°€ëŠ¥.

> ğŸ’¡ LoRAëŠ” conditionë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ì €ì¥Â·ë°°í¬ ê°€ëŠ¥í•˜ë©°,  
> ìš©ëŸ‰ì´ ì‘ì•„ **ê³µìœ ì™€ ì¬ì‚¬ìš©ì´ ìš©ì´**í•˜ë‹¤.

---

### 3.3 Condition Embedding Network

CtrLoRAì˜ í•µì‹¬ ì¤‘ í•˜ë‚˜ëŠ” **ì¡°ê±´(condition) ì´ë¯¸ì§€ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì„ë² ë”©**í•˜ëŠ” ë°©ì‹ì´ë‹¤.  
ê¸°ì¡´ ControlNetì€ ë‹¨ìˆœí•œ **ëœë¤ ì´ˆê¸°í™” CNN(convolutional encoder)** ë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ,  
CtrLoRAëŠ” **Stable Diffusionì˜ Pretrained VAE Encoder**ë¥¼ ê·¸ëŒ€ë¡œ í™œìš©í•œë‹¤.

```
Condition Image â†’ VAE Encoder â†’ Latent Representation (z_c)
â†“
Base ControlNet + LoRA ì…ë ¥
```



#### 3.3.1 ê¸°ì¡´ ControlNetì˜ í•œê³„
- ControlNetì€ condition imageë¥¼ featureë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´  
  **ì„ì˜ ì´ˆê¸°í™”ëœ CNN**ì„ ì‚¬ìš©.  
- í•™ìŠµ ì´ˆë°˜ì—ëŠ” ìœ ì˜ë¯¸í•œ í”¼ì²˜ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í•´,  
  **ìˆ˜ë ´ì´ ë§¤ìš° ëŠë¦¬ê³  ë¶ˆì•ˆì •í•¨**.  
- â€œSudden Convergenceâ€ í˜„ìƒ ë°œìƒ:  
  â†’ í•™ìŠµì´ ì¼ì • ë‹¨ê³„ê¹Œì§€ ì „í˜€ ì§„í–‰ë˜ì§€ ì•Šë‹¤ê°€,  
    ê°‘ìê¸° conditionì„ ê°•í•˜ê²Œ ë°˜ì˜í•˜ë©° í­ë°œì ìœ¼ë¡œ ìˆ˜ë ´í•¨.

> ğŸ’¡ ì´ í˜„ìƒì€ ì¡°ê±´ ì„ë² ë”© ë„¤íŠ¸ì›Œí¬ê°€  
> í•™ìŠµ ì´ˆê¸°ì— â€œë¬´ì˜ë¯¸í•œ latent ê³µê°„â€ì„ ë§Œë“¤ì–´ë‚´ê¸° ë•Œë¬¸ì„.



#### 3.3.2 Pretrained VAE Encoderì˜ ë„ì…
CtrLoRAëŠ” ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **Stable Diffusionì˜ VAE Encoder**ë¥¼ condition embedding networkë¡œ ì±„íƒí•˜ì˜€ë‹¤.  
ì¦‰, condition imageëŠ” VAE Encoderë¥¼ í†µí•´ ì¦‰ì‹œ **latent representation**ìœ¼ë¡œ ë³€í™˜ëœë‹¤.

\[
z_c = \text{VAE}_{enc}(c)
\]

- **VAE Encoder**ëŠ” ì›ë˜ ì´ë¯¸ì§€ë¥¼ latent spaceë¡œ ì••ì¶•í•˜ë„ë¡ í•™ìŠµë˜ì–´ ìˆìœ¼ë¯€ë¡œ,  
  ì´ë¯¸ ê°•ë ¥í•œ ì‹œê° í‘œí˜„(visual representation)ì„ ë³´ìœ .  
- Base ControlNetì€ Stable Diffusionì˜ Encoder êµ¬ì¡°ë¥¼ ë³µì œí•˜ì—¬ ì´ˆê¸°í™”í•˜ê¸° ë•Œë¬¸ì—,  
  ë‘ ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ ê³µê°„ì´ **ì •í™•íˆ ì •ë ¬(aligned)** ë˜ì–´ ìˆìŒ.  
- ì´ë¡œ ì¸í•´ condition featureê°€ **ë³„ë„ í•™ìŠµ ì—†ì´ë„ ì¦‰ì‹œ ì˜ë¯¸ ê³µê°„ì— ë§¤í•‘**ë¨.

| í•­ëª© | ê¸°ì¡´ ControlNet | CtrLoRA |
|------|------------------|----------|
| Condition Encoder | Random CNN | Pretrained VAE (SD Encoder) |
| ì´ˆê¸° ìˆ˜ë ´ ì†ë„ | ëŠë¦¼ / ë¶ˆì•ˆì • | ë¹ ë¦„ / ì•ˆì •ì  |
| Sudden Convergence | ì¡´ì¬ | ì œê±°ë¨ |
| í•™ìŠµ ì•ˆì •ì„± | ë‚®ìŒ | ë§¤ìš° ë†’ìŒ |



#### 3.3.3 íš¨ê³¼ ë° ì¥ì 
- **ë¹ ë¥¸ ìˆ˜ë ´**: í•™ìŠµ ì´ˆê¸°ë¶€í„° ì˜ë¯¸ ìˆëŠ” condition featureë¥¼ ì „ë‹¬í•¨.  
- **í›ˆë ¨ ì•ˆì •ì„± í–¥ìƒ**: gradient í­ì£¼ë‚˜ loss ì§„ë™ í˜„ìƒ ê°ì†Œ.  
- **ì •í™•í•œ feature alignment**: VAE latent spaceì™€ ControlNet ì…ë ¥ ê³µê°„ì´ ì¼ì¹˜.  
- **ì¶”ê°€ í•™ìŠµ ë¶ˆí•„ìš”**: VAEëŠ” ì´ë¯¸ SDì—ì„œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë“ˆì´ë¯€ë¡œ, ì¬í•™ìŠµ ì—†ì´ ë°”ë¡œ í™œìš© ê°€ëŠ¥.

> ğŸ’¡ ê²°ê³¼ì ìœ¼ë¡œ, CtrLoRAëŠ” condition embeddingì„  
> â€œpretrained latent encoder â†’ immediate alignmentâ€ í˜•íƒœë¡œ ë‹¨ìˆœí™”í•˜ì—¬  
> í•™ìŠµ íš¨ìœ¨ê³¼ ì•ˆì •ì„±ì„ ë™ì‹œì— í™•ë³´í–ˆë‹¤.

---

### 3.4 Inference (Multi-Conditional Generation)

CtrLoRAì˜ ì¶”ë¡ (inference)ì€ **Base ControlNet**ê³¼ **ì—¬ëŸ¬ ì¡°ê±´ë³„ LoRA ëª¨ë“ˆ**ì„  
ë™ì‹œì— ì¡°í•©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì´ë‹¤.  
Stable Diffusionì˜ denoising ê³¼ì • ìœ„ì—ì„œ ë™ì‘í•˜ë©°,  
ê° LoRAì˜ ì¶œë ¥ì„ **ê°€ì¤‘í•©(weighted sum)** í•˜ì—¬ ìµœì¢… ì œì–´ ì‹ í˜¸ë¡œ ì‚¬ìš©í•œë‹¤.

```
Condition 1 (Segmentation) â”
Condition 2 (Lighting) â”œâ”€â”€> ê° LoRA â†’ Feature Map
Condition 3 (Normal) â”˜
â†“
Base ControlNet (shared)
â†“
UNet Denoiser â†’ Diffusion Sampling
â†“
VAE Decoder â†’ ìµœì¢… ì´ë¯¸ì§€

```


#### 3.4.1 Multi-Conditional Feature Aggregation

ì—¬ëŸ¬ LoRAë¥¼ ë™ì‹œì— ì ìš©í•  ë•Œ,  
ê° LoRAëŠ” ë™ì¼í•œ Base ControlNetì˜ feature mapì— ëŒ€í•´  
ì¡°ê±´ë³„ ì”ì°¨(residual)ë¥¼ ìƒì„±í•˜ê³  ì´ë¥¼ í•©ì‚°í•œë‹¤.

\[
C_{\theta, \Psi}(z, c) = C_{\theta}(z) + \sum_{i=1}^{N} w_i \cdot L_{\psi_i}(z, c_i)
\]

- \( C_{\theta} \): Base ControlNet  
- \( L_{\psi_i} \): ië²ˆì§¸ conditionì˜ LoRA  
- \( w_i \): í•´ë‹¹ ì¡°ê±´ì˜ ê°€ì¤‘ì¹˜(weight, ê¸°ë³¸ê°’ 1.0)  
- \( z \): latent representation  
- \( c_i \): ê° condition imageì˜ embedding  

> ğŸ’¡ ì´ êµ¬ì¡° ë•ë¶„ì—, ì—¬ëŸ¬ ì¡°ê±´(ì˜ˆ: segmentation + lighting + pose)ì„  
> ë³„ë„ ë„¤íŠ¸ì›Œí¬ ë³‘í•© ì—†ì´ ë‹¨ì¼ forward passë¡œ í†µí•© ê°€ëŠ¥í•˜ë‹¤.



#### 3.4.2 Denoising Process

CtrLoRAëŠ” Stable Diffusionì˜ denoising ê³¼ì •ê³¼ ë™ì¼í•˜ê²Œ ì‘ë™í•œë‹¤.  
Base ControlNetê³¼ LoRAì˜ ì¶œë ¥ì„ UNetì— ì£¼ì…í•˜ì—¬  
latent ê³µê°„ì—ì„œ ë…¸ì´ì¦ˆë¥¼ ì ì§„ì ìœ¼ë¡œ ì œê±°í•œë‹¤.

\[
\epsilon_\theta(x_t, c) = D(E(x_t), C_{\theta, \Psi}(z, c))
\]

- \( x_t \): ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ latent ì´ë¯¸ì§€  
- \( E, D \): Stable Diffusionì˜ Encoder/Decoder  
- \( C_{\theta, \Psi} \): Base ControlNet + LoRA ì¡°í•©  
- ì¶œë ¥: ë‹¤ìŒ timestepìœ¼ë¡œ ì „ë‹¬ë  ë…¸ì´ì¦ˆ ì˜ˆì¸¡ê°’  

Samplingì€ ì¼ë°˜ì ìœ¼ë¡œ **DDIM (50 steps)** ë˜ëŠ” **DPM-Solver**ë¥¼ ì‚¬ìš©í•˜ë©°,  
Classifier-Free Guidance Scaleì€ **7.5** ì „í›„ë¡œ ì„¤ì •í•œë‹¤.



#### 3.4.3 Conditional Strength & Guidance

ê° LoRAì˜ ê¸°ì—¬ë„ëŠ” ê°€ì¤‘ì¹˜ \( w_i \)ë¡œ ì¡°ì ˆ ê°€ëŠ¥í•˜ë©°,  
ì´ ê°’ì„ ë†’ì¼ìˆ˜ë¡ í•´ë‹¹ ì¡°ê±´ì˜ ì˜í–¥ë ¥ì´ ì»¤ì§„ë‹¤.

| Condition | Weight (ì˜ˆì‹œ) | ê²°ê³¼ |
|------------|----------------|------|
| Segmentation | 1.0 | êµ¬ì¡°ì  í˜•íƒœ ìœ ì§€ |
| Lighting | 0.5 | ìƒ‰ìƒ ë° ìŒì˜ë§Œ ë¶€ë¶„ ë°˜ì˜ |
| Normal | 0.3 | í‘œë©´ ë°©í–¥ê°ë§Œ ì•½í•˜ê²Œ ë°˜ì˜ |

> ğŸ’¡ â€œê°€ì¤‘ì¹˜ ì¡°ì ˆâ€ì€ ControlNetì˜ strength ê°œë…ê³¼ ìœ ì‚¬í•˜ë©°,  
> ì—¬ëŸ¬ ì¡°ê±´ì˜ ë°¸ëŸ°ìŠ¤ë¥¼ ì§ì ‘ ì œì–´í•  ìˆ˜ ìˆë‹¤.  



#### 3.4.4 Inference Pipeline Summary
1. **Condition Encoding**: ëª¨ë“  condition image â†’ VAE Encoder â†’ latent embedding ìƒì„±  
2. **LoRA Aggregation**: ê° LoRAì˜ ì¶œë ¥ weighted sum â†’ Base ControlNet featureì— ì£¼ì…  
3. **UNet Denoising**: Stable Diffusionì˜ latent spaceì—ì„œ noise ì œê±°  
4. **Decoding**: ìµœì¢… latent â†’ VAE Decoder â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë³µì›  

---

> ğŸ’¡ ê²°ê³¼

